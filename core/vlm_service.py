"""
VLMè°ƒç”¨æœåŠ¡ï¼ˆDashScope APIå°è£…ï¼‰
æ³¨æ„ï¼šéœ€è¦å®‰è£… pip install dashscope --break-system-packages
"""

from typing import Dict, List, Any, Optional
import json

# å°è¯•å¯¼å…¥dashscopeï¼Œå¦‚æœæœªå®‰è£…åˆ™æä¾›mock
try:
    import dashscope
    from dashscope import MultiModalConversation
    DASHSCOPE_AVAILABLE = True
except ImportError:
    DASHSCOPE_AVAILABLE = False
    print("Warning: dashscope not installed. Using mock VLM service.")

from config.settings import Settings
from core.utils import app_logger, extract_json_from_text


class VLMService:
    """VLMè°ƒç”¨æœåŠ¡"""
    
    def __init__(self):
        if DASHSCOPE_AVAILABLE:
            dashscope.api_key = Settings.DASHSCOPE_API_KEY
        self.model = Settings.VLM_MODEL
        self.max_tokens = Settings.VLM_MAX_TOKENS
        self.temperature = Settings.VLM_TEMPERATURE
        app_logger.info(f"VLM Service initialized: {self.model}")
    
    def call(self, messages: List[Dict], system_prompt: str = None, 
             expect_json: bool = False) -> Dict:
        """è°ƒç”¨VLM"""
        if not DASHSCOPE_AVAILABLE:
            return self._mock_call(messages, system_prompt, expect_json)
        
        try:
            api_messages = self._prepare_messages(messages, system_prompt)
            response = MultiModalConversation.call(
                model=self.model,
                messages=api_messages,
                max_tokens=self.max_tokens,
                temperature=self.temperature
            )
            
            if response.status_code == 200:
                content = response.output.choices[0].message.content[0]["text"]
                
                # ğŸ“Š æ·»åŠ æ—¥å¿—ï¼šæ‰“å°VLMåŸå§‹è¾“å‡º
                app_logger.info(f"ğŸ¤– VLMåŸå§‹è¾“å‡ºå‰500å­—ç¬¦: {content[:500]}")
                
                result = {"success": True, "content": content}
                if expect_json:
                    result["parsed_json"] = extract_json_from_text(content)
                return result
            else:
                # ğŸ“Š æ·»åŠ æ—¥å¿—ï¼šæ‰“å°é”™è¯¯è¯¦æƒ…
                app_logger.error(f"âŒ VLM APIé”™è¯¯: status={response.status_code}, message={response.message}")
                return {"success": False, "error": response.message}
        except Exception as e:
            app_logger.error(f"âŒ VLMè°ƒç”¨å¼‚å¸¸: {str(e)}", exc_info=True)
            return {"success": False, "error": str(e)}
    
    def _prepare_messages(self, messages: List, system_prompt: str = None) -> List:
        """å‡†å¤‡APIæ¶ˆæ¯æ ¼å¼"""
        api_messages = []
        if system_prompt:
            api_messages.append({"role": "system", "content": [{"text": system_prompt}]})
        
        for msg in messages:
            role = msg.get("role", "user")
            content = msg.get("content", [])
            if isinstance(content, str):
                content = [{"text": content}]
            api_messages.append({"role": role, "content": content})
        return api_messages
    
    def _mock_call(self, messages, system_prompt, expect_json):
        """Mockè°ƒç”¨ï¼ˆç”¨äºæµ‹è¯•ï¼‰"""
        mock_response = {
            "success": True,
            "content": "è¿™æ˜¯ä¸€ä¸ªæ¨¡æ‹Ÿå“åº”ã€‚è¯·å®‰è£…dashscopeåŒ…ä»¥ä½¿ç”¨çœŸå®çš„VLMæœåŠ¡ã€‚"
        }
        if expect_json:
            mock_response["parsed_json"] = {"mock": True}
        return mock_response
    
    def call_with_image(self, text: str, image_base64: str, 
                       system_prompt: str = None, expect_json: bool = False):
        """ä¾¿æ·æ–¹æ³•ï¼šæ–‡æœ¬+å›¾åƒ"""
        messages = [{
            "role": "user",
            "content": [
                {"text": text},
                {"image": f"data:image/png;base64,{image_base64}"}
            ]
        }]
        return self.call(messages, system_prompt, expect_json)
    
    def call_text_only(self, text: str, system_prompt: str = None, 
                       expect_json: bool = False):
        """ä¾¿æ·æ–¹æ³•ï¼šä»…æ–‡æœ¬"""
        messages = [{"role": "user", "content": [{"text": text}]}]
        return self.call(messages, system_prompt, expect_json)


_vlm_service = None

def get_vlm_service() -> VLMService:
    """è·å–VLMæœåŠ¡å•ä¾‹"""
    global _vlm_service
    if _vlm_service is None:
        _vlm_service = VLMService()
    return _vlm_service
