"""
é€šç”¨VLMä½¿ç”¨ç¤ºä¾‹
æ¼”ç¤ºå¦‚ä½•è®©ä»»æ„VLMï¼ˆOpenAI GPT-4V, Claude, Geminiç­‰ï¼‰ä½¿ç”¨å¯è§†åŒ–åˆ†æå·¥å…·
"""

import json
import sys
import os
from typing import Dict, Any, List

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
sys.path.insert(0, os.path.abspath(os.path.join(os.path.dirname(__file__), '..')))

from tools.vlm_adapter import vlm_adapter
from tools.tool_executor import get_tool_executor
from config.chart_types import ChartType


class GenericVLMVisualAnalyzer:
    """
    é€šç”¨VLMå¯è§†åŒ–åˆ†æå™¨
    å¯ä»¥æ¥å…¥ä»»ä½•æ”¯æŒfunction callingæˆ–æç¤ºè¯çš„VLM
    """
    
    def __init__(self, chart_type: ChartType = None):
        """
        åˆå§‹åŒ–åˆ†æå™¨
        
        Args:
            chart_type: å›¾è¡¨ç±»å‹ï¼ˆå¯é€‰ï¼Œç”¨äºé™å®šå·¥å…·èŒƒå›´ï¼‰
        """
        self.adapter = vlm_adapter
        self.executor = get_tool_executor()
        self.chart_type = chart_type
        self.conversation_history = []
    
    def get_tools_for_openai(self) -> List[Dict[str, Any]]:
        """
        è·å–OpenAIæ ¼å¼çš„å·¥å…·å®šä¹‰
        é€‚ç”¨äº: GPT-4, GPT-4V, GPT-4-turboç­‰
        """
        return self.adapter.to_openai_format(self.chart_type)
    
    def get_tools_for_anthropic(self) -> List[Dict[str, Any]]:
        """
        è·å–Anthropicæ ¼å¼çš„å·¥å…·å®šä¹‰
        é€‚ç”¨äº: Claude 3 Opus, Sonnet, Haikuç­‰
        """
        return self.adapter.to_anthropic_format(self.chart_type)
    
    def get_tools_as_prompt(self) -> str:
        """
        è·å–æç¤ºè¯æ ¼å¼çš„å·¥å…·è¯´æ˜
        é€‚ç”¨äº: ä¸æ”¯æŒfunction callingçš„VLM
        """
        return self.adapter.to_prompt_string(self.chart_type)
    
    def execute_tool_call(self, tool_name: str, params: Dict[str, Any]) -> Dict[str, Any]:
        """
        æ‰§è¡Œå·¥å…·è°ƒç”¨
        
        Args:
            tool_name: å·¥å…·åç§°
            params: å·¥å…·å‚æ•°ï¼ˆå¿…é¡»åŒ…å«vega_specï¼‰
            
        Returns:
            å·¥å…·æ‰§è¡Œç»“æœ
        """
        result = self.executor.execute(tool_name, params)
        return result
    
    def parse_tool_calls_from_response(self, response_text: str) -> List[Dict[str, Any]]:
        """
        ä»VLMå“åº”ä¸­è§£æå·¥å…·è°ƒç”¨
        æ”¯æŒJSONå’Œä»£ç å—æ ¼å¼
        
        Args:
            response_text: VLMçš„æ–‡æœ¬å“åº”
            
        Returns:
            è§£æå‡ºçš„å·¥å…·è°ƒç”¨åˆ—è¡¨
        """
        tool_calls = []
        
        # å°è¯•æå–JSONä»£ç å—
        import re
        json_blocks = re.findall(r'```json\n(.*?)\n```', response_text, re.DOTALL)
        
        for block in json_blocks:
            try:
                data = json.loads(block)
                if isinstance(data, dict) and 'tool' in data:
                    tool_calls.append(data)
                elif isinstance(data, list):
                    tool_calls.extend([item for item in data if isinstance(item, dict) and 'tool' in item])
            except json.JSONDecodeError:
                continue
        
        return tool_calls


# ============================================================================
# ä½¿ç”¨ç¤ºä¾‹ 1: OpenAI GPT-4V
# ============================================================================

def example_openai_gpt4v():
    """
    ç¤ºä¾‹: ä½¿ç”¨OpenAI GPT-4Vè¿›è¡Œå¯è§†åŒ–åˆ†æ
    """
    print("=" * 60)
    print("ç¤ºä¾‹ 1: OpenAI GPT-4V")
    print("=" * 60)
    
    # åˆå§‹åŒ–åˆ†æå™¨
    analyzer = GenericVLMVisualAnalyzer(chart_type=ChartType.SCATTER_PLOT)
    
    # è·å–å·¥å…·å®šä¹‰ï¼ˆOpenAIæ ¼å¼ï¼‰
    tools = analyzer.get_tools_for_openai()
    
    print("\nâœ“ å·²ç”Ÿæˆ OpenAI æ ¼å¼çš„å·¥å…·å®šä¹‰")
    print(f"âœ“ å¯ç”¨å·¥å…·æ•°é‡: {len(tools)}")
    print(f"âœ“ ç¤ºä¾‹å·¥å…·: {tools[0]['function']['name']}")
    
    # æ¨¡æ‹Ÿè°ƒç”¨ï¼ˆå®é™…ä½¿ç”¨æ—¶éœ€è¦OpenAI APIï¼‰
    """
    from openai import OpenAI
    client = OpenAI(api_key="your-api-key")
    
    # å‡†å¤‡æ¶ˆæ¯
    messages = [
        {
            "role": "user",
            "content": [
                {"type": "text", "text": "åˆ†æè¿™ä¸ªæ•£ç‚¹å›¾çš„èšç±»æƒ…å†µ"},
                {"type": "image_url", "image_url": {"url": f"data:image/png;base64,{image_base64}"}}
            ]
        }
    ]
    
    # è°ƒç”¨GPT-4V with tools
    response = client.chat.completions.create(
        model="gpt-4-vision-preview",
        messages=messages,
        tools=tools,
        tool_choice="auto"
    )
    
    # å¤„ç†å·¥å…·è°ƒç”¨
    if response.choices[0].message.tool_calls:
        for tool_call in response.choices[0].message.tool_calls:
            tool_name = tool_call.function.name
            tool_args = json.loads(tool_call.function.arguments)
            
            # æ‰§è¡Œå·¥å…·
            result = analyzer.execute_tool_call(tool_name, tool_args)
            print(f"å·¥å…· {tool_name} æ‰§è¡Œç»“æœ:", result)
    """
    
    print("\nğŸ“ OpenAI é›†æˆä»£ç å·²åœ¨æ³¨é‡Šä¸­æä¾›")


# ============================================================================
# ä½¿ç”¨ç¤ºä¾‹ 2: Anthropic Claude
# ============================================================================

def example_anthropic_claude():
    """
    ç¤ºä¾‹: ä½¿ç”¨Anthropic Claudeè¿›è¡Œå¯è§†åŒ–åˆ†æ
    """
    print("\n" + "=" * 60)
    print("ç¤ºä¾‹ 2: Anthropic Claude")
    print("=" * 60)
    
    analyzer = GenericVLMVisualAnalyzer(chart_type=ChartType.SCATTER_PLOT)
    
    # è·å–å·¥å…·å®šä¹‰ï¼ˆAnthropicæ ¼å¼ï¼‰
    tools = analyzer.get_tools_for_anthropic()
    
    print("\nâœ“ å·²ç”Ÿæˆ Anthropic æ ¼å¼çš„å·¥å…·å®šä¹‰")
    print(f"âœ“ å¯ç”¨å·¥å…·æ•°é‡: {len(tools)}")
    print(f"âœ“ ç¤ºä¾‹å·¥å…·: {tools[0]['name']}")
    
    # æ¨¡æ‹Ÿè°ƒç”¨ï¼ˆå®é™…ä½¿ç”¨æ—¶éœ€è¦Anthropic APIï¼‰
    """
    import anthropic
    client = anthropic.Anthropic(api_key="your-api-key")
    
    # å‡†å¤‡æ¶ˆæ¯
    message = client.messages.create(
        model="claude-3-opus-20240229",
        max_tokens=1024,
        tools=tools,
        messages=[
            {
                "role": "user",
                "content": [
                    {
                        "type": "image",
                        "source": {
                            "type": "base64",
                            "media_type": "image/png",
                            "data": image_base64
                        }
                    },
                    {
                        "type": "text",
                        "text": "åˆ†æè¿™ä¸ªæ•£ç‚¹å›¾ï¼Œæ‰¾å‡ºèšç±»æ¨¡å¼"
                    }
                ]
            }
        ]
    )
    
    # å¤„ç†å·¥å…·ä½¿ç”¨
    if message.stop_reason == "tool_use":
        for content in message.content:
            if content.type == "tool_use":
                tool_name = content.name
                tool_input = content.input
                
                # æ‰§è¡Œå·¥å…·
                result = analyzer.execute_tool_call(tool_name, tool_input)
                print(f"å·¥å…· {tool_name} æ‰§è¡Œç»“æœ:", result)
    """
    
    print("\nğŸ“ Anthropic é›†æˆä»£ç å·²åœ¨æ³¨é‡Šä¸­æä¾›")


# ============================================================================
# ä½¿ç”¨ç¤ºä¾‹ 3: é€šç”¨VLMï¼ˆä½¿ç”¨æç¤ºè¯ï¼‰
# ============================================================================

def example_generic_vlm_with_prompt():
    """
    ç¤ºä¾‹: ä½¿ç”¨ä¸æ”¯æŒfunction callingçš„VLMï¼ˆé€šè¿‡æç¤ºè¯ï¼‰
    """
    print("\n" + "=" * 60)
    print("ç¤ºä¾‹ 3: é€šç”¨VLMï¼ˆæç¤ºè¯æ–¹å¼ï¼‰")
    print("=" * 60)
    
    analyzer = GenericVLMVisualAnalyzer(chart_type=ChartType.SCATTER_PLOT)
    
    # è·å–å·¥å…·æç¤ºè¯
    tools_prompt = analyzer.get_tools_as_prompt()
    
    print("\nâœ“ å·²ç”Ÿæˆå·¥å…·æç¤ºè¯")
    print(f"âœ“ æç¤ºè¯é•¿åº¦: {len(tools_prompt)} å­—ç¬¦")
    print("\nå‰300å­—ç¬¦é¢„è§ˆ:")
    print("-" * 60)
    print(tools_prompt[:300] + "...")
    print("-" * 60)
    
    # æ¨¡æ‹Ÿå¯¹è¯
    system_prompt = f"""ä½ æ˜¯ä¸€ä¸ªå¯è§†åŒ–åˆ†æåŠ©æ‰‹ã€‚

{tools_prompt}

å½“éœ€è¦ä½¿ç”¨å·¥å…·æ—¶ï¼Œè¯·æŒ‰ç…§ä¸Šè¿°æ ¼å¼è¿”å›JSONã€‚
"""
    
    print("\nğŸ“ å°†æ­¤æç¤ºè¯æ·»åŠ åˆ°VLMçš„system promptä¸­")
    print("ğŸ“ VLMä¼šè¿”å›JSONæ ¼å¼çš„å·¥å…·è°ƒç”¨ï¼Œç„¶åè§£æå¹¶æ‰§è¡Œ")
    
    # æ¨¡æ‹Ÿè§£æå·¥å…·è°ƒç”¨
    example_response = """
æˆ‘éœ€è¦å…ˆè¯†åˆ«æ•£ç‚¹å›¾ä¸­çš„èšç±»ã€‚

```json
{
  "tool": "identify_clusters",
  "params": {
    "vega_spec": {...},
    "n_clusters": 3,
    "method": "kmeans"
  },
  "reason": "è¯†åˆ«æ•°æ®ä¸­çš„3ä¸ªä¸»è¦èšç±»æ¨¡å¼"
}
```
"""
    
    tool_calls = analyzer.parse_tool_calls_from_response(example_response)
    print(f"\nâœ“ æˆåŠŸè§£æ {len(tool_calls)} ä¸ªå·¥å…·è°ƒç”¨")
    if tool_calls:
        print(f"âœ“ å·¥å…·åç§°: {tool_calls[0]['tool']}")


# ============================================================================
# å®Œæ•´å·¥ä½œæµç¤ºä¾‹
# ============================================================================

def example_complete_workflow():
    """
    å®Œæ•´çš„åˆ†æå·¥ä½œæµç¤ºä¾‹
    """
    print("\n" + "=" * 60)
    print("ç¤ºä¾‹ 4: å®Œæ•´åˆ†æå·¥ä½œæµ")
    print("=" * 60)
    
    # 1. åŠ è½½å›¾è¡¨æ•°æ®
    print("\næ­¥éª¤ 1: åŠ è½½Vega-Liteå›¾è¡¨")
    vega_spec = {
        "$schema": "https://vega.github.io/schema/vega-lite/v5.json",
        "data": {
            "values": [
                {"x": 1, "y": 2}, {"x": 2, "y": 4},
                {"x": 3, "y": 6}, {"x": 4, "y": 8}
            ]
        },
        "mark": "point",
        "encoding": {
            "x": {"field": "x", "type": "quantitative"},
            "y": {"field": "y", "type": "quantitative"}
        }
    }
    print("âœ“ å›¾è¡¨å·²åŠ è½½")
    
    # 2. åˆå§‹åŒ–åˆ†æå™¨
    print("\næ­¥éª¤ 2: åˆå§‹åŒ–åˆ†æå™¨")
    analyzer = GenericVLMVisualAnalyzer(chart_type=ChartType.SCATTER_PLOT)
    print("âœ“ åˆ†æå™¨å·²åˆå§‹åŒ–")
    
    # 3. è·å–å·¥å…·åˆ—è¡¨
    print("\næ­¥éª¤ 3: è·å–å¯ç”¨å·¥å…·")
    tools_openai = analyzer.get_tools_for_openai()
    print(f"âœ“ OpenAIæ ¼å¼å·¥å…·: {len(tools_openai)} ä¸ª")
    
    # 4. æ‰§è¡Œåˆ†æå·¥å…·
    print("\næ­¥éª¤ 4: æ‰§è¡Œæ•°æ®æ‘˜è¦å·¥å…·")
    result = analyzer.execute_tool_call(
        "get_data_summary",
        {"vega_spec": vega_spec, "scope": "all"}
    )
    
    if result['success']:
        print("âœ“ å·¥å…·æ‰§è¡ŒæˆåŠŸ")
        print(f"  æ•°æ®ç‚¹æ•°é‡: {result.get('count', 'N/A')}")
        print(f"  ç»Ÿè®¡ä¿¡æ¯: {list(result.get('summary', {}).keys())}")
    else:
        print(f"âœ— å·¥å…·æ‰§è¡Œå¤±è´¥: {result.get('error')}")
    
    print("\n" + "=" * 60)
    print("âœ“ å®Œæ•´å·¥ä½œæµæ¼”ç¤ºå®Œæˆ")
    print("=" * 60)


# ============================================================================
# ä¸»å‡½æ•°
# ============================================================================

def main():
    """è¿è¡Œæ‰€æœ‰ç¤ºä¾‹"""
    print("\n" + "=" * 60)
    print("é€šç”¨VLMå¯è§†åŒ–åˆ†æå·¥å…· - ä½¿ç”¨ç¤ºä¾‹")
    print("=" * 60)
    
    # è¿è¡Œæ‰€æœ‰ç¤ºä¾‹
    example_openai_gpt4v()
    example_anthropic_claude()
    example_generic_vlm_with_prompt()
    example_complete_workflow()
    
    print("\n" + "=" * 60)
    print("æ‰€æœ‰ç¤ºä¾‹è¿è¡Œå®Œæˆ!")
    print("=" * 60)
    print("\næç¤º:")
    print("1. æŸ¥çœ‹ä¸Šè¿°ç¤ºä¾‹ä»£ç ï¼Œäº†è§£å¦‚ä½•é›†æˆä¸åŒçš„VLM")
    print("2. å–æ¶ˆæ³¨é‡Šç›¸åº”çš„APIè°ƒç”¨ä»£ç ")
    print("3. å¡«å…¥ä½ çš„APIå¯†é’¥")
    print("4. è¿è¡Œå®é™…çš„åˆ†æä»»åŠ¡")
    print("\nè¯¦ç»†æ–‡æ¡£: è¯·æŸ¥çœ‹ README.md")


if __name__ == "__main__":
    main()
